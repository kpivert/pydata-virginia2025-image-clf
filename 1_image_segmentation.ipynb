{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "569dff8f",
   "metadata": {},
   "source": [
    "# Image Segmentation Demo\n",
    "Order of Operations for Image Segmentation\n",
    "\n",
    "\n",
    "1. Preprocessing:\n",
    "Noise Reduction: Apply filtering techniques (e.g., Gaussian blur) to remove noise from the image.\n",
    "Intensity Normalization: Adjust the intensity levels to improve contrast and highlight features.\n",
    "Resizing: Scale the image if necessary to a consistent size for further processing.\n",
    "\n",
    "2. Feature Extraction:\n",
    "Extract relevant features from the image that will help in distinguishing between different segments. This may include:\n",
    "Color information (RGB, HSV)\n",
    "Texture features (e.g., texture descriptors, edge detection)\n",
    "Shape descriptors\n",
    "\n",
    "3. Segmentation Method Selection:\n",
    "Choose an appropriate segmentation method based on the specific application and characteristics of the images. Common methods include:\n",
    "Thresholding\n",
    "Region-based segmentation (e.g., region growing, merging)\n",
    "Clustering-based methods (e.g., k-means, mean shift)\n",
    "Edge detection methods (e.g., Canny edge detection)\n",
    "Machine Learning / Deep Learning approaches (e.g., U-Net, Mask R-CNN)\n",
    "\n",
    "4. Segmentation Execution:\n",
    "Apply the selected segmentation algorithm to the preprocessed image to divide it into distinct segments or regions.\n",
    "\n",
    "\n",
    "Our first step is to load the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f33e49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, feature, segmentation, color, restoration, filters, transform, measure, morphology, draw, exposure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5105df",
   "metadata": {},
   "source": [
    "## Example 1: Noise reduction / smoothing / thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47af61ff",
   "metadata": {},
   "source": [
    "Next let's read our images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019c6bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'test_seg_images/k75Kf715A9h6p4S60682_2D_img02560-LOC-2d-0-512_1024-1536.tiff'\n",
    "image = io.imread(file_path)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77ee7e1",
   "metadata": {},
   "source": [
    "Look at Equalizing Gamma or Adaptive Equalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff5256c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_image = exposure.adjust_gamma(image, gamma=1, gain=1)\n",
    "clahe_image = exposure.equalize_adapthist(image)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(7, 4))\n",
    "\n",
    "ax[0].imshow(gamma_image, cmap='gray')\n",
    "ax[0].set_title('Gamma image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(clahe_image, cmap='gray')\n",
    "ax[1].set_title('CLAHE equalized image')\n",
    "ax[1].axis('off')\n",
    "plt.subplots_adjust()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e52cd53",
   "metadata": {},
   "source": [
    "The gamma image looks to have identifiable levels - let's go with it.\n",
    "\n",
    "Now let's apply Multi-threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e81d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_image = filters.gaussian(gamma_image, sigma=31, truncate=1/5)\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.title('gaussian blur')\n",
    "plt.imshow(blur_image, cmap='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a43a7e",
   "metadata": {},
   "source": [
    "We've smoothed out a lot of artifacts, now let's apply our multi-otsu threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12d99d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = filters.threshold_multiotsu(blur_image)\n",
    "regions = np.digitize(blur_image, bins=thresholds)\n",
    "\n",
    "# threshold_global_otsu = filters.threshold_otsu(blur_image)\n",
    "# global_otsu_binary = blur_image >= threshold_global_otsu\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(7, 4))\n",
    "ax[0].imshow(blur_image, cmap='gray')\n",
    "ax[0].set_title('gaussian blur')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(regions)\n",
    "ax[1].set_title('multi-otsu threshold')\n",
    "ax[1].axis('off')\n",
    "plt.subplots_adjust()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f84ffb",
   "metadata": {},
   "source": [
    "There's a lot of small artifacts in the image so let's remove those\n",
    "\n",
    "Also use normal otsu thresholding (binary) to remove the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71484ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_global_otsu = filters.threshold_otsu(blur_image)\n",
    "global_otsu_binary = blur_image >= threshold_global_otsu\n",
    "\n",
    "# we're only interested in the first region captured by the threshold\n",
    "multi_otsu_regions = (regions == 0)\n",
    "\n",
    "# Remove small artifacts\n",
    "large_objects = morphology.remove_small_objects(multi_otsu_regions, min_size=500)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(8, 4))\n",
    "ax[0].imshow(blur_image, cmap='gray')\n",
    "ax[0].set_title('gaussian blur')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(global_otsu_binary)\n",
    "ax[1].set_title('otsu thres')\n",
    "ax[1].axis('off')\n",
    "\n",
    "ax[2].imshow(multi_otsu_regions)\n",
    "ax[2].set_title('multi-otsu threshold')\n",
    "ax[2].axis('off')\n",
    "\n",
    "ax[3].imshow(large_objects)\n",
    "ax[3].set_title('large features')\n",
    "ax[3].axis('off')\n",
    "plt.subplots_adjust()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f4f6dc",
   "metadata": {},
   "source": [
    "Now let's apply the mask to the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c4966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_image = image * (large_objects == 1)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(7, 4))\n",
    "ax[0].imshow(image, cmap='gray')\n",
    "ax[0].set_title('original image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(masked_image)\n",
    "ax[1].set_title('masked image')\n",
    "ax[1].axis('off')\n",
    "plt.subplots_adjust()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7c4d3e",
   "metadata": {},
   "source": [
    "## Example 2\n",
    "\n",
    "In this example let's utilize morphological operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a268403",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'test_seg_images/73305IX3JqLNR72O9O46_2D_img01769-LOC-2d-1024-1536_1024-1536.tiff'\n",
    "image = io.imread(file_path)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d5f820",
   "metadata": {},
   "source": [
    "Clean the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337ccd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "clahe_image = exposure.equalize_adapthist(image)\n",
    "blur_image = filters.gaussian(clahe_image, sigma=11, truncate=1/5)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(7, 4))\n",
    "ax[0].imshow(image, cmap='gray')\n",
    "ax[0].set_title('original image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(blur_image, cmap='gray')\n",
    "ax[1].set_title('clahe/blurred image')\n",
    "ax[1].axis('off')\n",
    "plt.subplots_adjust()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d391aaf",
   "metadata": {},
   "source": [
    "Lets apply multi-otsu to find the regions of interest.  Also let's remove small artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91092aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Otsu - create mask on background\n",
    "thresholds = filters.threshold_multiotsu(blur_image)\n",
    "regions = np.digitize(blur_image, bins=thresholds)\n",
    "\n",
    "multi_otsu_regions = (regions == 0)\n",
    "large_objects = morphology.remove_small_objects(multi_otsu_regions, min_size=2000)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(7, 4))\n",
    "ax[0].imshow(blur_image, cmap='gray')\n",
    "ax[0].set_title('gaussian blur')\n",
    "ax[0].axis('off')\n",
    "\n",
    "\n",
    "ax[1].imshow(large_objects)\n",
    "ax[1].set_title('multi-otsu threshold')\n",
    "ax[1].axis('off')\n",
    "plt.subplots_adjust()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa41b15",
   "metadata": {},
   "source": [
    "Our mask is not closed in some regions, so let's apply dilations to cover the regions of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f641bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "footprint = morphology.disk(17)\n",
    "dilated_image = morphology.binary_dilation(large_objects, footprint)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(7, 4))\n",
    "ax[0].imshow(large_objects)\n",
    "ax[0].set_title('multi-otsu threshold')\n",
    "ax[0].axis('off')\n",
    "\n",
    "\n",
    "ax[1].imshow(dilated_image)\n",
    "ax[1].set_title('dilated image')\n",
    "ax[1].axis('off')\n",
    "plt.subplots_adjust()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d174a309",
   "metadata": {},
   "source": [
    "Now let's apply our mask to the original image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4689f367",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_image = image * (dilated_image == 1)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(7, 4))\n",
    "ax[0].imshow(image, cmap='gray')\n",
    "ax[0].set_title('original image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(masked_image)\n",
    "ax[1].set_title('masked image')\n",
    "ax[1].axis('off')\n",
    "plt.subplots_adjust()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f7f78c",
   "metadata": {},
   "source": [
    "## Example 3\n",
    "\n",
    "Let's look at some advanced segmententing techniques from scikit learn and scikit-image.  \n",
    "\n",
    "First let's examine Gaussian Mixture Model (GMM) segmentation.\n",
    "\n",
    "First we read the image and both apply histogram equalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206b6655",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'test_seg_images/k75Kf715A9h6p4S60682_2D_img02560-LOC-2d-0-512_1024-1536.tiff'\n",
    "\n",
    "# Load and preprocess the image\n",
    "image = io.imread(file_path)\n",
    "\n",
    "clahe_image = exposure.equalize_adapthist(image, kernel_size=11, clip_limit=0.01) #contrast enhancement\n",
    "blur_image = filters.gaussian(clahe_image, sigma=33, truncate=1/5)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(7, 4))\n",
    "ax[0].imshow(image, cmap='gray')\n",
    "ax[0].set_title('original image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(blur_image, cmap='gray')\n",
    "ax[1].set_title('clahe/blur')\n",
    "ax[1].axis('off')\n",
    "plt.subplots_adjust()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47891d46",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9770768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "n_components = 3  # 3 classes for segmentation\n",
    "\n",
    "rows, cols = np.shape(blur_image)\n",
    "\n",
    "# reshape the image array to num_observations by num_features (1,000,000 by 3)\n",
    "X = blur_image.reshape(-1,1)\n",
    "\n",
    "# Create and train our Gaussian Mixture Expectation Maximization Model\n",
    "model = GaussianMixture(n_components=3, tol=0.1)\n",
    "model.fit(X)\n",
    "\n",
    "# predict latent values\n",
    "yhat = model.predict(X)\n",
    "\n",
    "# reshape the result into an image\n",
    "gmm_thresh = np.reshape(yhat,[rows,cols])\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(7, 4))\n",
    "ax[0].imshow(blur_image, cmap='gray')\n",
    "ax[0].set_title('clahe/blur')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(gmm_thresh)\n",
    "ax[1].set_title('GMM thresh')\n",
    "ax[1].axis('off')\n",
    "plt.subplots_adjust()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fda56e",
   "metadata": {},
   "source": [
    "# Example 4\n",
    "\n",
    "Finally let's look at a really interesting new skimage algorithm called Weka Segmentation.\n",
    "\n",
    "Read in our image and augment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7560ad0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'test_seg_images/k75Kf715A9h6p4S60682_2D_img02560-LOC-2d-0-512_1024-1536.tiff'\n",
    "image = io.imread(file_path)\n",
    "#equalize = exposure.equalize_hist(image) #contrast enhancement\n",
    "\n",
    "clahe_image = exposure.equalize_adapthist(image, kernel_size=15, clip_limit=0.01) #contrast enhancement\n",
    "blur_image = filters.gaussian(clahe_image, sigma=33, truncate=1/5)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(7, 4))\n",
    "ax[0].imshow(image, cmap='gray')\n",
    "ax[0].set_title('original image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(blur_image, cmap='gray')\n",
    "ax[1].set_title('clahe/blur')\n",
    "ax[1].axis('off')\n",
    "plt.subplots_adjust()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07325868",
   "metadata": {},
   "source": [
    "Now let's assign dimensions to the regions of interest in the image we wish to segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4550fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels = np.zeros(blur_image.shape[:2], dtype=np.uint8)\n",
    "training_labels[:75] = 1\n",
    "training_labels[225:325, 175:300] = 2\n",
    "training_labels[200:290, 25:150] = 2\n",
    "training_labels[400:450, 200:240] = 3\n",
    "training_labels[370:390, 130:170] = 3\n",
    "training_labels[470:525, 130:150] = 3\n",
    "training_labels[380:420, 350:420] = 4\n",
    "\n",
    "fig = plt.figure(figsize=(7, 4))\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.contour(training_labels)\n",
    "plt.title('regions of interest')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f12de0",
   "metadata": {},
   "source": [
    "Now let's use our Random Forests Classifer to train on the ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c03b8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from functools import partial\n",
    "from skimage import filters, segmentation, feature, future, io, exposure\n",
    "\n",
    "sigma_min = 32\n",
    "sigma_max = 64\n",
    "features_func = partial(\n",
    "    feature.multiscale_basic_features, #Intensity, gradient intensity and local structure are computed at different scales thanks to Gaussian blurring.\n",
    "    intensity=True,\n",
    "    edges=False,\n",
    "    texture=True,\n",
    "    sigma_min=sigma_min,\n",
    "    sigma_max=sigma_max,\n",
    "    channel_axis=None,\n",
    ")\n",
    "features = features_func(blur_image)\n",
    "clf = RandomForestClassifier(n_estimators=50, n_jobs=-1, max_depth=100, max_samples=0.05)\n",
    "clf = future.fit_segmenter(training_labels, features, clf) #Segmentation using labeled parts of the image and a classifier\n",
    "result = future.predict_segmenter(features, clf)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(9, 4))\n",
    "ax[0].imshow(segmentation.mark_boundaries(blur_image, result, mode='thick'))\n",
    "ax[0].contour(training_labels)\n",
    "ax[0].set_title('image, mask and labeled boundaries')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(result)\n",
    "ax[1].set_title('Weka Segmentation')\n",
    "ax[1].axis('off')\n",
    "\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
