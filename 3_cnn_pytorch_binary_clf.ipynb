{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification with PyTorch CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Import classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import v2\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from skimage import io, exposure, color, img_as_float32\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like our last example  lets load our images from the folders and convert our labels to integers for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder_path):\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    for class_name in os.listdir(folder_path):\n",
    "        class_path = os.path.join(folder_path, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            for img_name in os.listdir(class_path):\n",
    "                img_path = os.path.join(class_path, img_name)\n",
    "\n",
    "                # Read image and convert to float32 to handle UInt16 data\n",
    "                img = io.imread(img_path)\n",
    "                images.append(img)\n",
    "                labels.append(class_name)\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "\n",
    "train_path = \"class_dataset/train\"\n",
    "test_path = \"class_dataset/test\"\n",
    "\n",
    "train_images, train_labels = load_images_from_folder(train_path)\n",
    "test_images, test_labels = load_images_from_folder(test_path)\n",
    "\n",
    "\n",
    "# Convert string labels to 0 and 1 integers\n",
    "unique_labels = np.unique(train_labels)\n",
    "label_map = {label: i for i, label in enumerate(unique_labels)}\n",
    "print(f\"Label mapping: {label_map}\")\n",
    "\n",
    "train_labels = np.array([label_map[label] for label in train_labels])\n",
    "test_labels = np.array([label_map[label] for label in test_labels])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's set up our dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class VirusDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = torch.from_numpy(labels).float().unsqueeze(1)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up our architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            # Adaptive pooling layer\n",
    "            nn.AdaptiveAvgPool2d((6, 6))\n",
    "        )\n",
    "        \n",
    "        # Fully connected layers block - output size changed to num_classes\n",
    "        self.fc_block = nn.Sequential(\n",
    "            nn.Linear(128 * 6 * 6, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(256, 1)  \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Apply convolutional features\n",
    "        x = self.features(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(-1, 128 * 6 * 6)\n",
    "        \n",
    "        # Apply fully connected block\n",
    "        x = self.fc_block(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to build our training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, tensorboard_writer=None):\n",
    "    \n",
    "    # send model to cpu or gpu\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} (Training)\"):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            # Ensure outputs and labels have the same shape for BCEWithLogitsLoss\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        # Calculate epoch loss\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} (Validation)\"):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "                \n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        val_preds = np.array(val_preds).flatten()\n",
    "        val_labels = np.array(val_labels).flatten()\n",
    "        \n",
    "        val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "        val_precision = precision_score(val_labels, val_preds, zero_division=0)\n",
    "        val_recall = recall_score(val_labels, val_preds, zero_division=0)\n",
    "        val_f1 = f1_score(val_labels, val_preds, zero_division=0)\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Val. Loss: {epoch_loss:.4f}, Val. Accuracy: {val_accuracy:.4f}\")\n",
    "        print(f\"Val. Precision: {val_precision:.4f}, Val. Recall: {val_recall:.4f}, Val. F1-Score: {val_f1:.4f}\")\n",
    "        \n",
    "        # Log to TensorBoard\n",
    "        if tensorboard_writer:\n",
    "            tensorboard_writer.add_scalar('Loss/train', epoch_loss, epoch)\n",
    "            tensorboard_writer.add_scalar('Metrics/accuracy', val_accuracy, epoch)\n",
    "            tensorboard_writer.add_scalar('Metrics/precision', val_precision, epoch)\n",
    "            tensorboard_writer.add_scalar('Metrics/recall', val_recall, epoch)\n",
    "            tensorboard_writer.add_scalar('Metrics/f1', val_f1, epoch)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply augmentations to our images with v2.  These apply to every image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2\n",
    "\n",
    "train_transform = v2.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "test_transform = v2.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready now to initalize our datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = VirusDataset(train_images, train_labels, transform=train_transform)\n",
    "test_dataset = VirusDataset(test_images, test_labels, transform=test_transform)\n",
    "\n",
    "# Split training data into train and validation\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=True, \n",
    "                          num_workers=0)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, \n",
    "                        batch_size=batch_size, \n",
    "                        shuffle=False, \n",
    "                        num_workers=0)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                         batch_size=batch_size, \n",
    "                         shuffle=False, \n",
    "                         num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initilize our model, loss function and optimizer.  Send model to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = CNNModel()\n",
    "criterion = BCEWithLogitsLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up TensorBoard\n",
    "run_id = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "log_dir = f\"runs/virus_cnn_experiment_{run_id}\"\n",
    "tensorboard_writer = SummaryWriter(log_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to train our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=5,\n",
    "    tensorboard_writer=tensorboard_writer\n",
    ")\n",
    "\n",
    "# Close TensorBoard writer\n",
    "tensorboard_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use our model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing model...\")\n",
    "model.eval()\n",
    "test_preds = []\n",
    "test_labels_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        \n",
    "        test_preds.extend(preds.cpu().numpy())\n",
    "        test_labels_list.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate and print test metrics\n",
    "test_preds = np.array(test_preds).flatten()\n",
    "test_labels_list = np.array(test_labels_list).flatten()\n",
    "\n",
    "print(\"\\nTest Results:\")\n",
    "print(classification_report(test_labels_list, test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a random sample from our test set and perform a prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select one test image\n",
    "test_data = list(zip(test_images, test_labels))\n",
    "random_sample = random.choice(test_data)\n",
    "\n",
    "# Unpack the randomly selected sample\n",
    "img, true_label = random_sample\n",
    "\n",
    "# reverse map to find label text\n",
    "reverse_map = {v: k for k, v in label_map.items()}\n",
    "true_label = reverse_map[true_label]\n",
    "\n",
    "# Preprocess the image for classification\n",
    "img_t = test_transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "# Generate prediction\n",
    "model.eval()\n",
    "\n",
    "# First forward pass - without gradients for prediction\n",
    "with torch.no_grad():\n",
    "    output = model(img_t)\n",
    "    prob = torch.sigmoid(output).item()\n",
    "    pred_class = 1 if prob > 0.5 else 0\n",
    "    pred_label = 'Influenza' if pred_class == 1 else 'Adenovirus'\n",
    "\n",
    "\n",
    "\n",
    "# Set up for saliency map calculation\n",
    "img_t.requires_grad_()\n",
    "\n",
    "# Forward pass\n",
    "output = model(img_t)\n",
    "output[0, output.argmax()].backward()\n",
    "\n",
    "# Create saliency map\n",
    "saliency_map = img_t.grad.data.abs().squeeze().cpu().numpy()\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(7, 4), constrained_layout=True)\n",
    "ax[0].imshow(img, cmap='gray')\n",
    "ax[0].set_title(f\"prediction: {pred_label}\\n true label: {true_label}\")\n",
    "ax[0].axis('off')\n",
    "\n",
    "# Plot saliency map\n",
    "saliency_plot = ax[1].imshow(saliency_map, cmap='jet')\n",
    "ax[1].set_title(\"saliency map\")\n",
    "ax[1].axis('off')\n",
    "\n",
    "# Add colorbar to the right of the saliency map\n",
    "plt.colorbar(saliency_plot, ax=ax, label='Gradient Magnitude')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
